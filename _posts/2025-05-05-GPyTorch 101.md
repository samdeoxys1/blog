---
layout: jupyter
title: "GPyTorch 101"
date: 2025-05-05
categories: tutorial notebooks
---

Recently I have been using AI to quickly prototype some complex Gaussian Process (GP) related models in GPytorch. While it does allow extremely fast prototyping, the workflow with prompting, testing and re-prompting often leave me this empty and anxious feeling, which is the opposite of the good solid feeling of building a model from ground up, line by line. So I decide to slow down and learn the basic building blocks of GPytorch. 

Another motivation for the notebook is that I want to try a new habit for learning. My old habit of learning is an iterative process of trying new models and understanding the math. However, when the new methods I tried did not make its way into my project, I moved on. Even though consciously I knew I still learned something, but the lack of tangible progress also added to the feeling of emptiness and anxiety. So instead of the endless chase of the final thing that works, I decide to document the journey more. Forcing myself to pause is not easy, when the brain is in the habit of trying the next tweak in the name of a deeper understanding. (This habit also makes paper writing harder to start.) But the pause is actually useful in many ways, as the chase often becomes mechanical (e.g. change a hyperparameter and press run and wait) and inefficient at the end of the day, while pausing and taking a step back creates the space my brain needs to see the fuller picture.  

With that said, in this notebook, I will to train the simplest Gaussian Process (GP) Regression model in GPytorch.


```python
import gpytorch
import torch
import matplotlib.pyplot as plt
import numpy as np
if torch.cuda.is_available():
    # 1. Pick your GPU (usually 0 if you have just one)
    torch.cuda.set_device(0)
    # 2. Make FloatTensors and DoubleTensors default to CUDA

    torch.set_default_dtype(torch.float32)   # optional, ensures float32
else:
    print("CUDA not available, falling back to CPU.")
    
# a helper function to turn the tensor on gpu to numpy on cpu
def strip(*args):
    to_return = tuple((x.detach().cpu().numpy() for x in args))
    if len(args)==1:
        return to_return[0]
    else:
        return to_return

```

First, to define a gpytorch model, we subclass some model from the gpytorch.models. For ExactGP, we need to initialize with the training x and y, as well as the likelihood. Next we need to assign the mean_module and covar_module, which are the mean and kernel functions that define the GP. Just like the regular pytorch models, it requires a forward method, which maps the input to the distribution of the output function evaluated at the input. The kernel here is a composition of ScaleKernel and RBFKernel. The former simply adds an output scale to the RBFKernel. This style of syntax highlights the compositionality in GPytorch, which is very principled but can also be a bit cumbersome at times.  


```python
class ExactGPModel(gpytorch.models.ExactGP):
    def __init__(self,train_x,train_y,likelihood):
        super().__init__(train_x,train_y,likelihood)
        self.mean_module = gpytorch.means.ConstantMean()
        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())
        
    def forward(self,x):
        mean_x = self.mean_module(x)
        covar_x = self.covar_module(x)
        return gpytorch.distributions.MultivariateNormal(mean_x,covar_x)
        
```

We will be generate some data from a ground truth ("teacher") GP and fit a "student" GP to see if we can recover the ground truth hyperparameters.  

We initialize the teacher GP with training data being None, together with the likelihood (which sets the observation noise). We use .initialize(hyperparam=xxx) to set relevant hyperparameters. 




```python
likelihood_true = gpytorch.likelihoods.GaussianLikelihood()
likelihood_true.noise_covar.initialize(noise=.01)
model_true=ExactGPModel(None,None,likelihood_true)
lengthscale_teacher=0.01
model_true.covar_module.base_kernel.initialize(lengthscale=lengthscale_teacher)
model_true.covar_module.initialize(outputscale=1)



```





Now we generate the actual training data using the teacher GP: evaluate the GP at some query points and sample. 



```python
train_x = torch.linspace(0, 1, 1000)
```


```python
model_true.eval()
train_y = likelihood_true(model_true(train_x)).sample()
```

Next, we initialize the student GP. In some cases we might not want to learn all hyperparameters, since the model could learn to increase one and decrease another to achieve the same fit (i.e. unidentifiability). We do this by doing model.covar_module.raw_outputscale.requires_grad_(False). Notice the "raw" here. Often the (hyper)parameters are constrained to be positive via some transform, but the optimization is done on the pre-transformed, unconstrained, "raw" (hyper)parameters. Conveniently, to initialize we can directly set the transformed (hyper)parameters.


```python
# student GP; init with the actual train test data
likelihood = gpytorch.likelihoods.GaussianLikelihood()
model = ExactGPModel(train_x,train_y,likelihood)


model.covar_module.base_kernel.initialize(lengthscale=1.)

likelihood.noise_covar.initialize(noise=1.)


model.covar_module.initialize(outputscale=1)
model.covar_module.raw_outputscale.requires_grad_(False)

```




To train, first toggle the .train for model **and likelihood**. Gather the trainable parameters in both model and likelihood, and set up the loss from gpytorch.mlls. The rest is the same as normal pytorch!


```python
from itertools import chain
model.train()
likelihood.train()

optimizer =torch.optim.Adam(chain(model.parameters(),likelihood.parameters()),lr=0.1)
mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood,model)

training_iter = 50
lengthscale_history = []
loss_history=[]
for i in range(training_iter):
    optimizer.zero_grad()
    output = model(train_x)
    loss = -mll(output,train_y)
    loss.backward()
    print(f'Iter {i}, loss {loss.item()},lengthscale {model.covar_module.base_kernel.lengthscale.item()}, noise {likelihood.noise.item()}')                  
    lengthscale_history.append(model.covar_module.base_kernel.lengthscale.item())
    loss_history.append(loss.item())
    optimizer.step()
lengthscale_history=np.array(lengthscale_history)
```


```python
fig,axs=plt.subplots(1,2,figsize=(5,2))
ax=axs[0]
ax.plot(loss_history)
ax.set_title('Loss')
ax=axs[1]
ax.plot(lengthscale_history)
ax.set_title('Lengthscale')
ax.axhline(lengthscale_teacher,label='lengthscale_teacher',c='k')
ax.legend(bbox_to_anchor=[1.05,1])
ax.set_xlabel('Training iter.')
plt.tight_layout()
```


    
![png]({{ site.baseurl }}/images/gpytorch_101/output_14_0.png)
    


Lengthscale is correctly recovered!

(You might notice the loss does not seem to converge here and wonder why I don't train for longer. That is becuase when I tried to train for longer, I inevitably run into some warning about conjugate gradient having abnormal norm, and the loss will jump to super huge. I don't understand what's going on...)

To make predictions, **we need to call model_true.eval() here!** Under the .train() mode, the forward pass gives the *prior* distribution of the output, whereas .eval() gives the *posterior* distribution of the output! This is a big difference with usual pytorch models, where the change from .train to .eval might not be so huge. 


```python
model.eval()
with torch.no_grad(), gpytorch.settings.fast_pred_var():
    y_hat = likelihood(model(train_x))
    y_hat_mean=y_hat.mean
    lower,upper=y_hat.confidence_region()


train_x_np=strip(train_x)
train_y_np = strip(train_y)
y_hat_mean_np = strip(y_hat_mean)
lower,upper = strip(lower,upper)
```


```python
fig,ax=plt.subplots()
ax.plot(train_x_np,train_y_np,'k*',alpha=1.,ms=1,label='Data')
ax.plot(train_x_np,y_hat_mean_np,label='Pred. mean')
ax.fill_between(train_x_np,lower,upper,alpha=.5,label='Pred. CI')
ax.legend()
```




    <matplotlib.legend.Legend at 0x15541fa59df0>




    
![png]({{ site.baseurl }}/images/gpytorch_101/output_18_1.png)
    


Isn't this beautiful?

